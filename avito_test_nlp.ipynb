{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13117041,"sourceType":"datasetVersion","datasetId":8309289}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Задача: Восстановление пропущенных пробелов в тексте с помощью NLP / DL / алгоритма.","metadata":{}},{"cell_type":"markdown","source":"## Описание окружения и подготовки\n\n### Используемое окружение\nРабота выполнялась в Kaggle-ноутбуке с использованием ускорителя **GPU T4 x2** для повышения производительности вычислений. Это позволило ускорить обучение модели и обработку данных.\n\n### Установка и импорт библиотек\nДля выполнения задачи были установлены и импортированы необходимые библиотеки. Установка выполнялась в Kaggle-ноутбуке с использованием команды `!pip install`, а импорт — через стандартный синтаксис Python.","metadata":{}},{"cell_type":"code","source":"!pip install Wikipedia-API","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:47:17.836933Z","iopub.execute_input":"2025-09-22T11:47:17.837502Z","iopub.status.idle":"2025-09-22T11:47:25.896172Z","shell.execute_reply.started":"2025-09-22T11:47:17.837477Z","shell.execute_reply":"2025-09-22T11:47:25.895433Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting Wikipedia-API\n  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from Wikipedia-API) (2.32.4)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->Wikipedia-API) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->Wikipedia-API) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->Wikipedia-API) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->Wikipedia-API) (2025.6.15)\nBuilding wheels for collected packages: Wikipedia-API\n  Building wheel for Wikipedia-API (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for Wikipedia-API: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=9a046c3cd6764fa2a181f51dc8d3e1911f51d8ac97c36b457d689770f3c974b2\n  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\nSuccessfully built Wikipedia-API\nInstalling collected packages: Wikipedia-API\nSuccessfully installed Wikipedia-API-0.8.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import logging\nfrom logging.handlers import RotatingFileHandler\nimport random\nimport torch\nimport time\nimport re\nimport wikipediaapi\nfrom uuid import uuid4\nfrom datasets import Dataset, DatasetDict\nfrom transformers import ByT5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq, T5Config\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T11:47:25.897591Z","iopub.execute_input":"2025-09-22T11:47:25.897858Z","iopub.status.idle":"2025-09-22T11:48:04.043999Z","shell.execute_reply.started":"2025-09-22T11:47:25.897835Z","shell.execute_reply":"2025-09-22T11:48:04.043238Z"}},"outputs":[{"name":"stderr","text":"2025-09-22 11:47:48.640138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758541668.961083      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758541669.054217      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Настройка логгера в Python с использованием модуля `logging`\n\nЭтот код настраивает систему логирования для записи сообщений в консоль и файл с использованием Python-модуля `logging`. Логгер используется для отслеживания событий во время выполнения программы, для вывода информации о процессе обучения модели.","metadata":{}},{"cell_type":"code","source":"logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogger.handlers.clear()  \n\nif not logger.handlers:\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n    console_handler.setFormatter(formatter)\n    log_file = 'word_segmentation.log'\n    file_handler = RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8')\n    file_handler.setLevel(logging.INFO)\n    file_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n    logger.addHandler(file_handler)\n    logger.info(\"Логгер успешно настроен\")","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:48:04.044841Z","iopub.execute_input":"2025-09-22T11:48:04.045465Z","iopub.status.idle":"2025-09-22T11:48:04.052149Z","shell.execute_reply.started":"2025-09-22T11:48:04.045436Z","shell.execute_reply":"2025-09-22T11:48:04.051499Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-09-22 11:48:04 - __main__ - INFO - Логгер успешно настроен\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Настройка воспроизводимости результатов и логирование\n\nЭтот код выполняет инициализацию генераторов случайных чисел для обеспечения воспроизводимости результатов в Python-программе, а также записывает соответствующее сообщение в лог.","metadata":{}},{"cell_type":"code","source":"random.seed(42)\ntorch.manual_seed(42)\nlogger.info(\"Инициализированы случайные seed для воспроизводимости результатов\")","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:48:04.053744Z","iopub.execute_input":"2025-09-22T11:48:04.053931Z","iopub.status.idle":"2025-09-22T11:48:04.092942Z","shell.execute_reply.started":"2025-09-22T11:48:04.053916Z","shell.execute_reply":"2025-09-22T11:48:04.092261Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-09-22 11:48:04 - __main__ - INFO - Инициализированы случайные seed для воспроизводимости результатов\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Описание функции `fetch_wiki_texts`\n\nФункция `fetch_wiki_texts` предназначена для загрузки текстовых фраз из Википедии на указанном языке, с определёнными критериями длины и случайными модификациями. Она используется для создания набора данных. Функция активно использует логирование для отслеживания процесса.\n\n### Параметры функции\n- **lang**: Код языка (например, `\"en\"` для английского, `\"ru\"` для русского).\n- **num_pages**: Количество фраз, которые нужно извлечь (по умолчанию 100).","metadata":{}},{"cell_type":"code","source":"def fetch_wiki_texts(lang, num_pages=100):\n    logger.info(f\"Загружаем {num_pages} коротких фраз из Википедии на языке: {lang}\")\n    start_time = time.time()\n    \n    #Создание объекта Википедии\n    \n    wiki = wikipediaapi.Wikipedia(\n        language=lang,\n        user_agent=f\"WordSegmentationBot/1.0 (https://x.ai; {uuid4()})\"\n    )\n    \n    #Список заголовков страниц\n    \n    page_titles = {\n        \"en\": [\n            \"Smartphone\", \"Laptop\", \"Coffee\", \"Chocolate\", \"Bicycle\",\n            \"Book\", \"Car\", \"Furniture\", \"Clothing\", \"Shoes\",\n            \"Graphics card\", \"Television\", \"Headphones\", \"Camera\", \"Tablet\",\n            \"Main Street\", \"Park Avenue\", \"Broadway\", \"Oxford Street\", \"Fifth Avenue\",\n            \"Times Square\", \"Trafalgar Square\", \"Piccadilly Circus\", \"Champs-Élysées\", \"Alexanderplatz\",\n            \"Shopping\", \"Restaurant\", \"Supermarket\", \"Bank\", \"Hospital\",\n            \"School\", \"University\", \"Hotel\", \"Airport\", \"Station\",\n            \"Market\", \"Lawyer\", \"Contract\", \"Warehouse\", \"Office\"\n        ],\n        \"ru\": [\n            \"Смартфон\", \"Ноутбук\", \"Кофе\", \"Шоколад\", \"Велосипед\",\n            \"Книга\", \"Автомобиль\", \"Мебель\", \"Одежда\", \"Обувь\",\n            \"Видеокарта\", \"Телевизор\", \"Наушники\", \"Камера\", \"Планшет\",\n            \"Тверская улица\", \"Невский проспект\", \"Арбат\", \"Кутузовский проспект\", \"Садовое кольцо\",\n            \"Красная площадь\", \"Манежная площадь\", \"Улица Горького\", \"Проспект Мира\", \"Ленинский проспект\",\n            \"Магазин\", \"Ресторан\", \"Супермаркет\", \"Банк\", \"Больница\",\n            \"Школа\", \"Университет\", \"Гостиница\", \"Аэропорт\", \"Вокзал\",\n            \"Рынок\", \"Юрист\", \"Договор\", \"Склад\", \"Офис\",  \"iPhone\",\"Бытовая техника\", \"Собака\", \n            \"Кровать\", \"Врач\", \"Стоматолог\", \"Мебель\", \"Московский метрополитен\", \"Рюкзак\", \n            \"Скейтборд\", \"Английский язык\", \"Ремонт\", \"Химия\", \"Парикмахер\", \"Автомобиль\", \n            \"Программирование\", \"Солнце\", \"Календарь\", \"Песня\", \"Чай\", \"Лампа накаливания\", \n            \"Герой\", \"Литература\", \"Смартфон\", \"Кофе\", \"Телевизор\", \"Университет\", \"Рынок\", \"Офис\"\n        ]\n    }.get(lang, [\n        \"Computer\", \"Phone\", \"Food\", \"City\", \"Street\",\n        \"Shop\", \"Market\", \"Bank\", \"School\", \"Transport\"\n    ])\n    \n    #Расширение списка заголовков\n    \n    page_titles = (page_titles * (num_pages // len(page_titles) + 1))[:num_pages * 2]\n    \n    #Извлечение текстов\n    \n    texts = []\n    successful = 0\n    for i, title in enumerate(page_titles, 1):\n        try:\n            page = wiki.page(title)\n            if page.exists():\n                content = page.text\n                sentences = re.split(r'[.!?]+', content)\n                \n                #Фильтрация и модификация предложений\n                \n                for sentence in sentences:\n                    clean = ' '.join(sentence.split()).strip()\n                    if  30<= len(clean) <=50:\n                        if random.random() < 0.2: \n                            words = clean.split()\n                            if len(words) > 1:\n                                pos = random.randint(1, len(words) - 1)\n                                clean = ' '.join(words[:pos]) + ', ' + ' '.join(words[pos:])\n                        if random.random() < 0.2:  \n                            clean += ' ' + str(random.randint(100, 300))\n                        texts.append(clean)\n                        successful += 1\n                        logger.debug(f\"Извлечена фраза из {title}: {clean} (длина: {len(clean)})\")\n                        \n                    #Обработка ошибок и пропуск страниц\n                    \n                    if successful >= num_pages:\n                        break\n                else:\n                    logger.debug(f\"Пропущена страница {title}: нет подходящих фраз\")\n            else:\n                logger.debug(f\"Пропущена страница {title}: не существует\")\n        except Exception as e:\n            logger.warning(f\"Ошибка при обработке страницы {title}: {str(e)}\")\n        if successful >= num_pages:\n            break\n            \n    #Дополнение недостающих фраз\n    \n    if len(texts) < num_pages:\n        logger.warning(f\"Извлечено только {len(texts)} фраз вместо {num_pages}. Дополняем...\")\n        while len(texts) < num_pages:\n            texts.append(random.choice(texts) if texts else f\"Sample text {lang} {len(texts)}\")\n    \n    logger.info(f\"Извлечено {len(texts)} фраз на {lang} за {time.time() - start_time:.2f} секунд\")\n    return texts[:num_pages]","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:48:04.093761Z","iopub.execute_input":"2025-09-22T11:48:04.093998Z","iopub.status.idle":"2025-09-22T11:48:04.107316Z","shell.execute_reply.started":"2025-09-22T11:48:04.093978Z","shell.execute_reply":"2025-09-22T11:48:04.106789Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Описание функции `generate_data`\n\nФункция `generate_data` создаёт датасет для задачи сегментации слов, комбинируя тексты на английском и русском языках, полученные из Википедии с помощью функции `fetch_wiki_texts`. Она формирует пары входных и выходных данных, где вход — текст без пробелов и запятых, а выход — исходный текст с пробелами.\n\n### Параметры функции\n- **num_samples**: Количество сгенерированных примеров (по умолчанию 5000).","metadata":{}},{"cell_type":"code","source":"def generate_data(num_samples=5000):\n    logger.info(\"Подготовка датасета\")\n\n    #Получение текстов из Википедии\n    \n    en_texts = fetch_wiki_texts('en', num_samples // 2)\n    ru_texts = fetch_wiki_texts('ru', num_samples // 2)\n    \n    if not en_texts or not ru_texts:\n        logger.error(\"Не удалось получить тексты из Википедии\")\n        raise ValueError(\"Не удалось получить тексты из Википедии\")\n\n    #Генерация датасета\n    \n    data = []\n    for _ in range(num_samples):\n        if random.random() < 0.3:  # 30% mixed\n            en_sent = random.choice(en_texts)\n            ru_sent = random.choice(ru_texts)\n            original = en_sent + ' ' + ru_sent\n        elif random.random() < 0.5:\n            original = random.choice(en_texts)\n        else:\n            original = random.choice(ru_texts)\n\n        #Формирование входных и выходных данных\n        \n        no_space = ''.join(original.replace(',', '').replace(' ', ''))\n        if len(no_space) <= 512:  # Проверка длины\n            input_text = f\"insert spaces: {no_space}\"\n            data.append({\"input\": input_text, \"output\": original})\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:48:04.107988Z","iopub.execute_input":"2025-09-22T11:48:04.108241Z","iopub.status.idle":"2025-09-22T11:48:04.131818Z","shell.execute_reply.started":"2025-09-22T11:48:04.108218Z","shell.execute_reply":"2025-09-22T11:48:04.131317Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Описание процесса подготовки датасета\n\nЭтот код выполняет подготовку датасета для машинного обучения, используя функцию `generate_data` (описанную ранее), преобразует данные в объект `Dataset` из библиотеки Hugging Face `datasets`, разделяет его на обучающую и валидационную выборки, и логирует результаты. ","metadata":{}},{"cell_type":"code","source":"logger.info(\"Подготовка датасета\")\nstart_time = time.time()\ndata = generate_data(12000) \ndataset = Dataset.from_list(data)\nsplit = dataset.train_test_split(test_size=0.1)\ndataset_dict = DatasetDict({\"train\": split[\"train\"], \"validation\": split[\"test\"]})\nlogger.info(f\"Датасет подготовлен: {len(dataset_dict['train'])} обучающих, {len(dataset_dict['validation'])} валидационных примеров за {time.time() - start_time:.2f} секунд\")","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:48:04.132422Z","iopub.execute_input":"2025-09-22T11:48:04.132720Z","iopub.status.idle":"2025-09-22T11:50:15.125107Z","shell.execute_reply.started":"2025-09-22T11:48:04.132702Z","shell.execute_reply":"2025-09-22T11:50:15.124423Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-09-22 11:48:04 - __main__ - INFO - Подготовка датасета\n2025-09-22 11:48:04 - __main__ - INFO - Подготовка датасета\n2025-09-22 11:48:04 - __main__ - INFO - Загружаем 6000 коротких фраз из Википедии на языке: en\n2025-09-22 11:49:16 - __main__ - INFO - Извлечено 6000 фраз на en за 72.21 секунд\n2025-09-22 11:49:16 - __main__ - INFO - Загружаем 6000 коротких фраз из Википедии на языке: ru\n2025-09-22 11:50:15 - __main__ - INFO - Извлечено 6000 фраз на ru за 58.65 секунд\n2025-09-22 11:50:15 - __main__ - INFO - Датасет подготовлен: 10800 обучающих, 1200 валидационных примеров за 130.97 секунд\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Описание процесса загрузки модели и токенизатора\n\nЭтот код выполняет загрузку предобученной модели `google/byt5-small` и её токенизатора из библиотеки Hugging Face `transformers` для задачи обработки текста, например, сегментации слов. Процесс сопровождается логированием времени выполнения. \n\n## Выбор модели `google/byt5-small`\n\nДля задачи сегментации слов была выбрана модель `google/byt5-small` из-за её компактного размера, что делает её подходящей для работы в Kaggle-ноутбуке с ускорителем GPU T4 x2 (16 ГБ памяти). Модель `google/byt5-base`, имеющая больший размер, не использовалась из-за ограничений по памяти GPU, которые приводили к ошибкам нехватки памяти при загрузке и обучении.\n\n### Причины выбора\n- **Меньший размер**: `byt5-small` требует меньше памяти GPU, что позволяет эффективно выполнять обучение и инференс на доступном оборудовании.\n- **Ограничения Kaggle**: GPU T4 x2 имеет ограниченный объём памяти, и более крупная модель `byt5-base` вызывала ошибки типа `CUDA out of memory`.","metadata":{}},{"cell_type":"code","source":"model_name = \"google/byt5-small\"\nlogger.info(f\"Загружаем модель и токенизатор: {model_name}\")\nstart_time = time.time()\ntokenizer = ByT5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)\nlogger.info(f\"Модель и токенизатор загружены за {time.time() - start_time:.2f} секунд\")","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:50:15.125927Z","iopub.execute_input":"2025-09-22T11:50:15.126180Z","iopub.status.idle":"2025-09-22T11:50:24.847779Z","shell.execute_reply.started":"2025-09-22T11:50:15.126148Z","shell.execute_reply":"2025-09-22T11:50:24.846993Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-09-22 11:50:15 - __main__ - INFO - Загружаем модель и токенизатор: google/byt5-small\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e40789e49e14f709a180600fb6f7ffe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eecb32d9a4943a384f22b1dc366d773"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cf66979983349468f08744aca5bd469"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74df4f8023b647cf9779603a458ba1df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ce6d53bd3245d58e2026664363ce02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a095a6a9284c88a0e0c94608f51c8c"}},"metadata":{}},{"name":"stderr","text":"2025-09-22 11:50:24 - __main__ - INFO - Модель и токенизатор загружены за 9.71 секунд\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Описание функции `preprocess`\n\nФункция `preprocess` выполняет токенизацию входных и выходных данных датасета для подготовки к обучению модели `google/byt5-small`. Она используется для обработки текстов, созданных функцией `generate_data`, в формате, подходящем для задачи сегментации слов. \n\n### Параметры функции\n- **examples**: Словарь (или объект `Dataset` из библиотеки `datasets`), содержащий ключи `\"input\"` и `\"output\"`.\n  - `\"input\"`: Текст с префиксом `\"insert spaces: ...\"`, например, `\"insert spaces: Helloworld\"`.\n  - `\"output\"`: Исходный текст с пробелами, например, `\"Hello world\"`.","metadata":{}},{"cell_type":"code","source":"def preprocess(examples):\n    inputs = tokenizer(examples[\"input\"], max_length=256, truncation=True)\n    labels = tokenizer(examples[\"output\"], max_length=256, truncation=True)\n    inputs[\"labels\"] = labels[\"input_ids\"]\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:50:24.848614Z","iopub.execute_input":"2025-09-22T11:50:24.848897Z","iopub.status.idle":"2025-09-22T11:50:24.864567Z","shell.execute_reply.started":"2025-09-22T11:50:24.848869Z","shell.execute_reply":"2025-09-22T11:50:24.862682Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Описание процесса токенизации датасета\n\nЭтот код выполняет токенизацию датасета, созданного ранее, используя функцию `preprocess` для подготовки данных к обучению модели `google/byt5-small`.","metadata":{}},{"cell_type":"code","source":"logger.info(\"Токенизация датасета\")\nstart_time = time.time()\ntokenized_datasets = dataset_dict.map(preprocess, batched=True)\nlogger.info(f\"Датасет токенизирован за {time.time() - start_time:.2f} секунд\")","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:50:24.873086Z","iopub.execute_input":"2025-09-22T11:50:24.873445Z","iopub.status.idle":"2025-09-22T11:50:31.752570Z","shell.execute_reply.started":"2025-09-22T11:50:24.873420Z","shell.execute_reply":"2025-09-22T11:50:31.751781Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-09-22 11:50:24 - __main__ - INFO - Токенизация датасета\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dec080cd9c449068355d6013501149b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d62a5114fb3499196301bf2f032cc33"}},"metadata":{}},{"name":"stderr","text":"2025-09-22 11:50:31 - __main__ - INFO - Датасет токенизирован за 6.80 секунд\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Описание процесса очистки датасета и логирования\n\nЭтот код выполняет удаление ненужных колонок (`\"input\"` и `\"output\"`) из токенизированного датасета, созданного ранее, и логирует изменения.\n\nЭти колонки содержат исходные текстовые данные (например, \"insert spaces: Helloworld\" и \"Hello world\"), которые больше не нужны после токенизации, так как данные уже преобразованы в `input_ids`, `attention_mask` и `labels`.","metadata":{}},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns([\"input\", \"output\"])\nlogger.info(\"Удалены ненужные колонки 'input' и 'output' из датасета\")\nlogger.info(f\"Обновлённые колонки train: {tokenized_datasets['train'].column_names}\")\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2025-09-22T11:50:31.753262Z","iopub.execute_input":"2025-09-22T11:50:31.753811Z","iopub.status.idle":"2025-09-22T11:50:31.765529Z","shell.execute_reply.started":"2025-09-22T11:50:31.753785Z","shell.execute_reply":"2025-09-22T11:50:31.764811Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-09-22 11:50:31 - __main__ - INFO - Удалены ненужные колонки 'input' и 'output' из датасета\n2025-09-22 11:50:31 - __main__ - INFO - Обновлённые колонки train: ['input_ids', 'attention_mask', 'labels']\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 10800\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 1200\n    })\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Описание инициализации Data Collator\n\nЭтот код инициализирует объект `DataCollatorForSeq2Seq` из библиотеки Hugging Face `transformers` для подготовки данных к обучению модели `google/byt5-small` в задаче последовательностного преобразования (sequence-to-sequence).","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\nlogger.info(\"Data collator инициализирован\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T11:50:31.766358Z","iopub.execute_input":"2025-09-22T11:50:31.766760Z","iopub.status.idle":"2025-09-22T11:50:37.990228Z","shell.execute_reply.started":"2025-09-22T11:50:31.766736Z","shell.execute_reply":"2025-09-22T11:50:37.989236Z"}},"outputs":[{"name":"stderr","text":"2025-09-22 11:50:37 - __main__ - INFO - Data collator инициализирован\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## Описание процесса обучения модели\n\nЭтот код выполняет обучение модели `google/byt5-small`. Он включает настройку загрузчиков данных, оптимизатора, планировщика скорости обучения, обучение с накоплением градиентов, периодическую валидацию и сохранение модели. Процесс сопровождается подробным логированием. \n\n### Параметры обучения\n- **EPOCHS**: `10` — количество эпох обучения.\n- **BATCH_SIZE**: `16` — размер батча.\n- **GRADIENT_ACCUMULATION_STEPS**: `2` — количество шагов накопления градиентов (эффективный размер батча = `BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS` = 32).\n- **LEARNING_RATE**: `2e-5` — скорость обучения.\n- **LOG_STEPS**: `50` — частота логирования метрик во время обучения.\n- **EVAL_STEPS**: `200` — частота выполнения валидации.\n- **WARMUP_STEPS**: `100` шагов  для постепенного увеличения скорости обучения.","metadata":{}},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\nlogger.info(\"Очищена кэшированная память GPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T11:50:37.991006Z","iopub.execute_input":"2025-09-22T11:50:37.991351Z","iopub.status.idle":"2025-09-22T11:50:38.878644Z","shell.execute_reply.started":"2025-09-22T11:50:37.991321Z","shell.execute_reply":"2025-09-22T11:50:38.877727Z"}},"outputs":[{"name":"stderr","text":"2025-09-22 11:50:38 - __main__ - INFO - Очищена кэшированная память GPU\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"EPOCHS = 10 \nBATCH_SIZE = 16  \nGRADIENT_ACCUMULATION_STEPS = 2  \nLEARNING_RATE = 2e-5  \nWARMUP_STEPS = 100 \nLOG_STEPS = 50\nEVAL_STEPS = 200\n\n#Создание загрузчиков данных\n\ntrain_dataloader = DataLoader(\n    tokenized_datasets['train'], \n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    collate_fn=data_collator,\n    num_workers=2,  \n    pin_memory=True  \n)\n\neval_dataloader = DataLoader(\n    tokenized_datasets['validation'], \n    batch_size=BATCH_SIZE,\n    collate_fn=data_collator,\n    num_workers=2,\n    pin_memory=True\n)\n\n#Настройка оптимизатора\n\noptimizer = optim.AdamW(\n    model.parameters(), \n    lr=LEARNING_RATE,\n    weight_decay=0.01,  \n    eps=1e-8 \n)\n\n#Настройка планировщика скорости обучения\n\nnum_training_steps = len(train_dataloader) * EPOCHS\nnum_warmup_steps = WARMUP_STEPS\n\nscheduler = optim.lr_scheduler.LambdaLR(\n    optimizer,\n    lr_lambda=lambda step: min(1.0, step / num_warmup_steps) if step < num_warmup_steps \n    else max(0.0, (num_training_steps - step) / (num_training_steps - num_warmup_steps))\n)\n\n#Логирование гиперпараметров\n\nlogger.info(f\"   Эпохи: {EPOCHS}\")\nlogger.info(f\"   Batch size: {BATCH_SIZE} (accumulation: {GRADIENT_ACCUMULATION_STEPS})\")\nlogger.info(f\"   Effective batch: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\nlogger.info(f\"   Learning rate: {LEARNING_RATE}\")\nlogger.info(f\"   Warmup steps: {num_warmup_steps}\")\nlogger.info(f\"   Всего шагов: {num_training_steps}\")\nlogger.info(\"=\" * 60)\n\n#Функция вычисления точности\n\ndef compute_accuracy(logits, labels):\n    predictions = torch.argmax(logits, dim=-1)\n    mask = labels != -100  \n    correct = (predictions == labels) & mask\n    accuracy = correct.sum().float() / mask.sum().float()\n    return accuracy.item()\n\n#Подготовка модели\n\nmodel.train()\nmodel.to('cuda') \n\n#Цикл обучения\n\nglobal_step = 0\nbest_eval_loss = float('inf')\ntotal_loss = 0\ngradient_accumulation_counter = 0\n\n#Внешний цикл по эпохам\n\nfor epoch in range(EPOCHS):\n    logger.info(f\"ЭПОХА {epoch + 1}/{EPOCHS} НАЧАЛАСЬ\")\n    epoch_loss = 0\n    epoch_accuracy = 0\n\n    #Внутренний цикл по батчам\n    \n    for step, batch in enumerate(train_dataloader):\n        batch = {k: v.to('cuda') for k, v in batch.items()}\n        \n        outputs = model(**batch)\n        loss = outputs.loss\n\n        #Нормировка потерь для накопления градиентов\n        \n        if GRADIENT_ACCUMULATION_STEPS > 1:\n            loss = loss / GRADIENT_ACCUMULATION_STEPS\n\n        #Обратное распространение\n        \n        loss.backward()\n        \n        gradient_accumulation_counter += 1\n        total_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n        epoch_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n\n        #Вычисление точности\n        \n        if hasattr(outputs, 'logits'):\n            accuracy = compute_accuracy(outputs.logits, batch['labels'])\n            epoch_accuracy += accuracy\n\n        #Обновление параметров модели\n        \n        if gradient_accumulation_counter % GRADIENT_ACCUMULATION_STEPS == 0:\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            \n            optimizer.step()\n            scheduler.step()\n            optimizer.zero_grad()\n            \n            global_step += 1\n\n            #Логирование каждые LOG_STEPS\n            \n            if global_step % LOG_STEPS == 0:\n                avg_loss = total_loss / LOG_STEPS\n                current_lr = scheduler.get_last_lr()[0]\n                logger.info(f\"Шаг {global_step:4d} | Эпоха {epoch + 1} | \"\n                           f\"Loss: {loss.item() * GRADIENT_ACCUMULATION_STEPS:.4f} | \"\n                           f\"Avg: {avg_loss:.4f} | LR: {current_lr:.2e} | \"\n                           f\"Accuracy: {accuracy:.3f}\")\n                total_loss = 0\n                \n            #Валидация\n            \n            if global_step % EVAL_STEPS == 0:\n                logger.info(f\"Валидация на шаге {global_step}...\")\n                model.eval()\n                eval_loss = 0\n                eval_accuracy = 0\n                eval_steps = 0\n                \n                with torch.no_grad():\n                    for eval_batch in eval_dataloader:\n                        eval_batch = {k: v.to('cuda') for k, v in eval_batch.items()}\n                        eval_outputs = model(**eval_batch)\n                        eval_loss += eval_outputs.loss.item()\n                        \n                        if hasattr(eval_outputs, 'logits'):\n                            eval_accuracy += compute_accuracy(eval_outputs.logits, eval_batch['labels'])\n                        \n                        eval_steps += 1\n                        \n                        if eval_steps >= 100:  \n                            break\n                \n                avg_eval_loss = eval_loss / eval_steps\n                avg_eval_accuracy = eval_accuracy / eval_steps\n                \n                logger.info(f\"Validation Loss: {avg_eval_loss:.4f} | Accuracy: {avg_eval_accuracy:.3f}\")\n                \n                if avg_eval_loss < best_eval_loss:\n                    best_eval_loss = avg_eval_loss\n                    logger.info(f\"Лучшее значение! Best Eval Loss: {best_eval_loss:.4f}\")\n                    \n                \n                model.train()\n\n    #Итоги эпохи\n    \n    avg_epoch_loss = epoch_loss / len(train_dataloader)\n    avg_epoch_accuracy = epoch_accuracy / len(train_dataloader)\n    \n    logger.info(f\"ЭПОХА {epoch + 1} ЗАВЕРШЕНА | \"\n               f\"Средний Loss: {avg_epoch_loss:.4f} | \"\n               f\"Accuracy: {avg_epoch_accuracy:.3f}\")\n    logger.info(\"-\" * 40)\n\n#Сохранение модели\n\nstate_dict = model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict()\ntorch.save({\n    'model_state_dict': state_dict,\n    'optimizer_state_dict': optimizer.state_dict(),\n    'scheduler_state_dict': scheduler.state_dict(),\n    'best_loss': best_eval_loss,\n    'final_epoch': EPOCHS,\n}, \"final_model.pt\")\ntokenizer.save_pretrained(\"final_model\")\nlogger.info(\"Финальная модель и токенизатор сохранены в 'final_model'\")\n\nlogger.info(\"=\" * 60)\nlogger.info(f\"Обучение завершено!\")\nlogger.info(f\"Лучший Eval Loss: {best_eval_loss:.4f}\")\nlogger.info(\"=\" * 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T11:51:22.778040Z","iopub.execute_input":"2025-09-22T11:51:22.778629Z","iopub.status.idle":"2025-09-22T14:25:43.254850Z","shell.execute_reply.started":"2025-09-22T11:51:22.778581Z","shell.execute_reply":"2025-09-22T14:25:43.253961Z"}},"outputs":[{"name":"stderr","text":"2025-09-22 11:51:22 - __main__ - INFO -    Эпохи: 10\n2025-09-22 11:51:22 - __main__ - INFO -    Batch size: 16 (accumulation: 2)\n2025-09-22 11:51:22 - __main__ - INFO -    Effective batch: 32\n2025-09-22 11:51:22 - __main__ - INFO -    Learning rate: 2e-05\n2025-09-22 11:51:22 - __main__ - INFO -    Warmup steps: 100\n2025-09-22 11:51:22 - __main__ - INFO -    Всего шагов: 6750\n2025-09-22 11:51:22 - __main__ - INFO - ============================================================\n2025-09-22 11:51:22 - __main__ - INFO - ЭПОХА 1/10 НАЧАЛАСЬ\n2025-09-22 11:53:29 - __main__ - INFO - Шаг   50 | Эпоха 1 | Loss: 1.5650 | Avg: 3.4290 | LR: 1.00e-05 | Accuracy: 0.676\n2025-09-22 11:55:38 - __main__ - INFO - Шаг  100 | Эпоха 1 | Loss: 0.9559 | Avg: 2.4416 | LR: 2.00e-05 | Accuracy: 0.781\n2025-09-22 11:57:47 - __main__ - INFO - Шаг  150 | Эпоха 1 | Loss: 0.6057 | Avg: 1.4441 | LR: 1.98e-05 | Accuracy: 0.868\n2025-09-22 11:59:57 - __main__ - INFO - Шаг  200 | Эпоха 1 | Loss: 0.3740 | Avg: 0.9345 | LR: 1.97e-05 | Accuracy: 0.898\n2025-09-22 11:59:57 - __main__ - INFO - Валидация на шаге 200...\n2025-09-22 12:00:31 - __main__ - INFO - Validation Loss: 0.1793 | Accuracy: 0.958\n2025-09-22 12:00:31 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.1793\n2025-09-22 12:02:41 - __main__ - INFO - Шаг  250 | Эпоха 1 | Loss: 0.2895 | Avg: 0.6713 | LR: 1.95e-05 | Accuracy: 0.919\n2025-09-22 12:04:50 - __main__ - INFO - Шаг  300 | Эпоха 1 | Loss: 0.2349 | Avg: 0.5445 | LR: 1.94e-05 | Accuracy: 0.938\n2025-09-22 12:06:27 - __main__ - INFO - ЭПОХА 1 ЗАВЕРШЕНА | Средний Loss: 0.7264 | Accuracy: 0.839\n2025-09-22 12:06:27 - __main__ - INFO - ----------------------------------------\n2025-09-22 12:06:27 - __main__ - INFO - ЭПОХА 2/10 НАЧАЛАСЬ\n2025-09-22 12:06:59 - __main__ - INFO - Шаг  350 | Эпоха 2 | Loss: 0.1885 | Avg: 0.4482 | LR: 1.92e-05 | Accuracy: 0.951\n2025-09-22 12:09:07 - __main__ - INFO - Шаг  400 | Эпоха 2 | Loss: 0.1851 | Avg: 0.3706 | LR: 1.91e-05 | Accuracy: 0.951\n2025-09-22 12:09:07 - __main__ - INFO - Валидация на шаге 400...\n2025-09-22 12:09:41 - __main__ - INFO - Validation Loss: 0.0791 | Accuracy: 0.980\n2025-09-22 12:09:41 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0791\n2025-09-22 12:11:51 - __main__ - INFO - Шаг  450 | Эпоха 2 | Loss: 0.1256 | Avg: 0.3278 | LR: 1.89e-05 | Accuracy: 0.963\n2025-09-22 12:14:00 - __main__ - INFO - Шаг  500 | Эпоха 2 | Loss: 0.1549 | Avg: 0.3071 | LR: 1.88e-05 | Accuracy: 0.953\n2025-09-22 12:16:09 - __main__ - INFO - Шаг  550 | Эпоха 2 | Loss: 0.1037 | Avg: 0.2739 | LR: 1.86e-05 | Accuracy: 0.970\n2025-09-22 12:18:18 - __main__ - INFO - Шаг  600 | Эпоха 2 | Loss: 0.0793 | Avg: 0.2574 | LR: 1.85e-05 | Accuracy: 0.981\n2025-09-22 12:18:18 - __main__ - INFO - Валидация на шаге 600...\n2025-09-22 12:18:52 - __main__ - INFO - Validation Loss: 0.0535 | Accuracy: 0.985\n2025-09-22 12:18:52 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0535\n2025-09-22 12:21:01 - __main__ - INFO - Шаг  650 | Эпоха 2 | Loss: 0.1455 | Avg: 0.2396 | LR: 1.83e-05 | Accuracy: 0.957\n2025-09-22 12:22:06 - __main__ - INFO - ЭПОХА 2 ЗАВЕРШЕНА | Средний Loss: 0.1478 | Accuracy: 0.958\n2025-09-22 12:22:06 - __main__ - INFO - ----------------------------------------\n2025-09-22 12:22:06 - __main__ - INFO - ЭПОХА 3/10 НАЧАЛАСЬ\n2025-09-22 12:23:11 - __main__ - INFO - Шаг  700 | Эпоха 3 | Loss: 0.0674 | Avg: 0.2192 | LR: 1.82e-05 | Accuracy: 0.980\n2025-09-22 12:25:19 - __main__ - INFO - Шаг  750 | Эпоха 3 | Loss: 0.0871 | Avg: 0.2121 | LR: 1.80e-05 | Accuracy: 0.971\n2025-09-22 12:27:29 - __main__ - INFO - Шаг  800 | Эпоха 3 | Loss: 0.0923 | Avg: 0.2050 | LR: 1.79e-05 | Accuracy: 0.979\n2025-09-22 12:27:29 - __main__ - INFO - Валидация на шаге 800...\n2025-09-22 12:28:02 - __main__ - INFO - Validation Loss: 0.0450 | Accuracy: 0.987\n2025-09-22 12:28:02 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0450\n2025-09-22 12:30:12 - __main__ - INFO - Шаг  850 | Эпоха 3 | Loss: 0.0940 | Avg: 0.1957 | LR: 1.77e-05 | Accuracy: 0.973\n2025-09-22 12:32:23 - __main__ - INFO - Шаг  900 | Эпоха 3 | Loss: 0.0931 | Avg: 0.1889 | LR: 1.76e-05 | Accuracy: 0.973\n2025-09-22 12:34:31 - __main__ - INFO - Шаг  950 | Эпоха 3 | Loss: 0.0828 | Avg: 0.1845 | LR: 1.74e-05 | Accuracy: 0.972\n2025-09-22 12:36:40 - __main__ - INFO - Шаг 1000 | Эпоха 3 | Loss: 0.0998 | Avg: 0.1806 | LR: 1.73e-05 | Accuracy: 0.971\n2025-09-22 12:36:40 - __main__ - INFO - Валидация на шаге 1000...\n2025-09-22 12:37:14 - __main__ - INFO - Validation Loss: 0.0407 | Accuracy: 0.988\n2025-09-22 12:37:14 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0407\n2025-09-22 12:37:46 - __main__ - INFO - ЭПОХА 3 ЗАВЕРШЕНА | Средний Loss: 0.0975 | Accuracy: 0.971\n2025-09-22 12:37:46 - __main__ - INFO - ----------------------------------------\n2025-09-22 12:37:46 - __main__ - INFO - ЭПОХА 4/10 НАЧАЛАСЬ\n2025-09-22 12:39:21 - __main__ - INFO - Шаг 1050 | Эпоха 4 | Loss: 0.0762 | Avg: 0.1704 | LR: 1.71e-05 | Accuracy: 0.979\n2025-09-22 12:41:31 - __main__ - INFO - Шаг 1100 | Эпоха 4 | Loss: 0.0957 | Avg: 0.1735 | LR: 1.70e-05 | Accuracy: 0.970\n2025-09-22 12:43:38 - __main__ - INFO - Шаг 1150 | Эпоха 4 | Loss: 0.1036 | Avg: 0.1660 | LR: 1.68e-05 | Accuracy: 0.969\n2025-09-22 12:45:47 - __main__ - INFO - Шаг 1200 | Эпоха 4 | Loss: 0.1025 | Avg: 0.1608 | LR: 1.67e-05 | Accuracy: 0.964\n2025-09-22 12:45:47 - __main__ - INFO - Валидация на шаге 1200...\n2025-09-22 12:46:21 - __main__ - INFO - Validation Loss: 0.0381 | Accuracy: 0.989\n2025-09-22 12:46:21 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0381\n2025-09-22 12:48:30 - __main__ - INFO - Шаг 1250 | Эпоха 4 | Loss: 0.0905 | Avg: 0.1602 | LR: 1.65e-05 | Accuracy: 0.968\n2025-09-22 12:50:39 - __main__ - INFO - Шаг 1300 | Эпоха 4 | Loss: 0.0675 | Avg: 0.1536 | LR: 1.64e-05 | Accuracy: 0.977\n2025-09-22 12:52:49 - __main__ - INFO - Шаг 1350 | Эпоха 4 | Loss: 0.0790 | Avg: 0.1501 | LR: 1.62e-05 | Accuracy: 0.978\n2025-09-22 12:52:49 - __main__ - INFO - ЭПОХА 4 ЗАВЕРШЕНА | Средний Loss: 0.0808 | Accuracy: 0.976\n2025-09-22 12:52:49 - __main__ - INFO - ----------------------------------------\n2025-09-22 12:52:49 - __main__ - INFO - ЭПОХА 5/10 НАЧАЛАСЬ\n2025-09-22 12:54:58 - __main__ - INFO - Шаг 1400 | Эпоха 5 | Loss: 0.0939 | Avg: 0.1523 | LR: 1.61e-05 | Accuracy: 0.977\n2025-09-22 12:54:58 - __main__ - INFO - Валидация на шаге 1400...\n2025-09-22 12:55:32 - __main__ - INFO - Validation Loss: 0.0354 | Accuracy: 0.990\n2025-09-22 12:55:32 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0354\n2025-09-22 12:57:42 - __main__ - INFO - Шаг 1450 | Эпоха 5 | Loss: 0.0516 | Avg: 0.1421 | LR: 1.59e-05 | Accuracy: 0.985\n2025-09-22 12:59:51 - __main__ - INFO - Шаг 1500 | Эпоха 5 | Loss: 0.0545 | Avg: 0.1408 | LR: 1.58e-05 | Accuracy: 0.985\n2025-09-22 13:02:00 - __main__ - INFO - Шаг 1550 | Эпоха 5 | Loss: 0.0656 | Avg: 0.1391 | LR: 1.56e-05 | Accuracy: 0.980\n2025-09-22 13:04:08 - __main__ - INFO - Шаг 1600 | Эпоха 5 | Loss: 0.0614 | Avg: 0.1387 | LR: 1.55e-05 | Accuracy: 0.981\n2025-09-22 13:04:08 - __main__ - INFO - Валидация на шаге 1600...\n2025-09-22 13:04:42 - __main__ - INFO - Validation Loss: 0.0341 | Accuracy: 0.990\n2025-09-22 13:04:42 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0341\n2025-09-22 13:06:50 - __main__ - INFO - Шаг 1650 | Эпоха 5 | Loss: 0.0711 | Avg: 0.1363 | LR: 1.53e-05 | Accuracy: 0.978\n2025-09-22 13:08:27 - __main__ - INFO - ЭПОХА 5 ЗАВЕРШЕНА | Средний Loss: 0.0704 | Accuracy: 0.979\n2025-09-22 13:08:27 - __main__ - INFO - ----------------------------------------\n2025-09-22 13:08:27 - __main__ - INFO - ЭПОХА 6/10 НАЧАЛАСЬ\n2025-09-22 13:09:00 - __main__ - INFO - Шаг 1700 | Эпоха 6 | Loss: 0.0520 | Avg: 0.1342 | LR: 1.52e-05 | Accuracy: 0.981\n2025-09-22 13:11:10 - __main__ - INFO - Шаг 1750 | Эпоха 6 | Loss: 0.0547 | Avg: 0.1299 | LR: 1.50e-05 | Accuracy: 0.982\n2025-09-22 13:13:18 - __main__ - INFO - Шаг 1800 | Эпоха 6 | Loss: 0.0557 | Avg: 0.1296 | LR: 1.49e-05 | Accuracy: 0.984\n2025-09-22 13:13:18 - __main__ - INFO - Валидация на шаге 1800...\n2025-09-22 13:13:52 - __main__ - INFO - Validation Loss: 0.0326 | Accuracy: 0.991\n2025-09-22 13:13:52 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0326\n2025-09-22 13:16:00 - __main__ - INFO - Шаг 1850 | Эпоха 6 | Loss: 0.0695 | Avg: 0.1234 | LR: 1.47e-05 | Accuracy: 0.976\n2025-09-22 13:18:08 - __main__ - INFO - Шаг 1900 | Эпоха 6 | Loss: 0.0678 | Avg: 0.1277 | LR: 1.46e-05 | Accuracy: 0.980\n2025-09-22 13:20:18 - __main__ - INFO - Шаг 1950 | Эпоха 6 | Loss: 0.0697 | Avg: 0.1238 | LR: 1.44e-05 | Accuracy: 0.976\n2025-09-22 13:22:27 - __main__ - INFO - Шаг 2000 | Эпоха 6 | Loss: 0.0424 | Avg: 0.1239 | LR: 1.43e-05 | Accuracy: 0.986\n2025-09-22 13:22:27 - __main__ - INFO - Валидация на шаге 2000...\n2025-09-22 13:23:01 - __main__ - INFO - Validation Loss: 0.0309 | Accuracy: 0.991\n2025-09-22 13:23:01 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0309\n2025-09-22 13:24:06 - __main__ - INFO - ЭПОХА 6 ЗАВЕРШЕНА | Средний Loss: 0.0631 | Accuracy: 0.981\n2025-09-22 13:24:06 - __main__ - INFO - ----------------------------------------\n2025-09-22 13:24:06 - __main__ - INFO - ЭПОХА 7/10 НАЧАЛАСЬ\n2025-09-22 13:25:11 - __main__ - INFO - Шаг 2050 | Эпоха 7 | Loss: 0.0539 | Avg: 0.1198 | LR: 1.41e-05 | Accuracy: 0.984\n2025-09-22 13:27:20 - __main__ - INFO - Шаг 2100 | Эпоха 7 | Loss: 0.0469 | Avg: 0.1156 | LR: 1.40e-05 | Accuracy: 0.983\n2025-09-22 13:29:31 - __main__ - INFO - Шаг 2150 | Эпоха 7 | Loss: 0.0535 | Avg: 0.1185 | LR: 1.38e-05 | Accuracy: 0.985\n2025-09-22 13:31:40 - __main__ - INFO - Шаг 2200 | Эпоха 7 | Loss: 0.0626 | Avg: 0.1200 | LR: 1.37e-05 | Accuracy: 0.986\n2025-09-22 13:31:40 - __main__ - INFO - Валидация на шаге 2200...\n2025-09-22 13:32:13 - __main__ - INFO - Validation Loss: 0.0294 | Accuracy: 0.991\n2025-09-22 13:32:13 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0294\n2025-09-22 13:34:22 - __main__ - INFO - Шаг 2250 | Эпоха 7 | Loss: 0.0570 | Avg: 0.1154 | LR: 1.35e-05 | Accuracy: 0.983\n2025-09-22 13:36:30 - __main__ - INFO - Шаг 2300 | Эпоха 7 | Loss: 0.0602 | Avg: 0.1124 | LR: 1.34e-05 | Accuracy: 0.982\n2025-09-22 13:38:38 - __main__ - INFO - Шаг 2350 | Эпоха 7 | Loss: 0.0399 | Avg: 0.1095 | LR: 1.32e-05 | Accuracy: 0.986\n2025-09-22 13:39:10 - __main__ - INFO - ЭПОХА 7 ЗАВЕРШЕНА | Средний Loss: 0.0576 | Accuracy: 0.983\n2025-09-22 13:39:10 - __main__ - INFO - ----------------------------------------\n2025-09-22 13:39:10 - __main__ - INFO - ЭПОХА 8/10 НАЧАЛАСЬ\n2025-09-22 13:40:47 - __main__ - INFO - Шаг 2400 | Эпоха 8 | Loss: 0.0383 | Avg: 0.1059 | LR: 1.31e-05 | Accuracy: 0.987\n2025-09-22 13:40:47 - __main__ - INFO - Валидация на шаге 2400...\n2025-09-22 13:41:21 - __main__ - INFO - Validation Loss: 0.0286 | Accuracy: 0.992\n2025-09-22 13:41:21 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0286\n2025-09-22 13:43:31 - __main__ - INFO - Шаг 2450 | Эпоха 8 | Loss: 0.0410 | Avg: 0.1100 | LR: 1.29e-05 | Accuracy: 0.990\n2025-09-22 13:45:40 - __main__ - INFO - Шаг 2500 | Эпоха 8 | Loss: 0.0636 | Avg: 0.1068 | LR: 1.28e-05 | Accuracy: 0.984\n2025-09-22 13:47:50 - __main__ - INFO - Шаг 2550 | Эпоха 8 | Loss: 0.0503 | Avg: 0.1071 | LR: 1.26e-05 | Accuracy: 0.984\n2025-09-22 13:49:59 - __main__ - INFO - Шаг 2600 | Эпоха 8 | Loss: 0.0557 | Avg: 0.1067 | LR: 1.25e-05 | Accuracy: 0.985\n2025-09-22 13:49:59 - __main__ - INFO - Валидация на шаге 2600...\n2025-09-22 13:50:33 - __main__ - INFO - Validation Loss: 0.0278 | Accuracy: 0.992\n2025-09-22 13:50:33 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0278\n2025-09-22 13:52:42 - __main__ - INFO - Шаг 2650 | Эпоха 8 | Loss: 0.0523 | Avg: 0.1078 | LR: 1.23e-05 | Accuracy: 0.983\n2025-09-22 13:54:50 - __main__ - INFO - Шаг 2700 | Эпоха 8 | Loss: 0.0671 | Avg: 0.1003 | LR: 1.22e-05 | Accuracy: 0.979\n2025-09-22 13:54:51 - __main__ - INFO - ЭПОХА 8 ЗАВЕРШЕНА | Средний Loss: 0.0532 | Accuracy: 0.984\n2025-09-22 13:54:51 - __main__ - INFO - ----------------------------------------\n2025-09-22 13:54:51 - __main__ - INFO - ЭПОХА 9/10 НАЧАЛАСЬ\n2025-09-22 13:57:00 - __main__ - INFO - Шаг 2750 | Эпоха 9 | Loss: 0.0400 | Avg: 0.1060 | LR: 1.20e-05 | Accuracy: 0.987\n2025-09-22 13:59:10 - __main__ - INFO - Шаг 2800 | Эпоха 9 | Loss: 0.0526 | Avg: 0.0976 | LR: 1.19e-05 | Accuracy: 0.982\n2025-09-22 13:59:10 - __main__ - INFO - Валидация на шаге 2800...\n2025-09-22 13:59:44 - __main__ - INFO - Validation Loss: 0.0268 | Accuracy: 0.992\n2025-09-22 13:59:44 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0268\n2025-09-22 14:01:52 - __main__ - INFO - Шаг 2850 | Эпоха 9 | Loss: 0.0486 | Avg: 0.0999 | LR: 1.17e-05 | Accuracy: 0.984\n2025-09-22 14:04:03 - __main__ - INFO - Шаг 2900 | Эпоха 9 | Loss: 0.0361 | Avg: 0.1007 | LR: 1.16e-05 | Accuracy: 0.986\n2025-09-22 14:06:12 - __main__ - INFO - Шаг 2950 | Эпоха 9 | Loss: 0.0550 | Avg: 0.0966 | LR: 1.14e-05 | Accuracy: 0.988\n2025-09-22 14:08:21 - __main__ - INFO - Шаг 3000 | Эпоха 9 | Loss: 0.0403 | Avg: 0.0993 | LR: 1.13e-05 | Accuracy: 0.987\n2025-09-22 14:08:21 - __main__ - INFO - Валидация на шаге 3000...\n2025-09-22 14:08:54 - __main__ - INFO - Validation Loss: 0.0260 | Accuracy: 0.993\n2025-09-22 14:08:54 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0260\n2025-09-22 14:10:32 - __main__ - INFO - ЭПОХА 9 ЗАВЕРШЕНА | Средний Loss: 0.0501 | Accuracy: 0.985\n2025-09-22 14:10:32 - __main__ - INFO - ----------------------------------------\n2025-09-22 14:10:32 - __main__ - INFO - ЭПОХА 10/10 НАЧАЛАСЬ\n2025-09-22 14:11:04 - __main__ - INFO - Шаг 3050 | Эпоха 10 | Loss: 0.0485 | Avg: 0.1006 | LR: 1.11e-05 | Accuracy: 0.985\n2025-09-22 14:13:14 - __main__ - INFO - Шаг 3100 | Эпоха 10 | Loss: 0.0471 | Avg: 0.0995 | LR: 1.10e-05 | Accuracy: 0.988\n2025-09-22 14:15:24 - __main__ - INFO - Шаг 3150 | Эпоха 10 | Loss: 0.0417 | Avg: 0.0951 | LR: 1.08e-05 | Accuracy: 0.986\n2025-09-22 14:17:31 - __main__ - INFO - Шаг 3200 | Эпоха 10 | Loss: 0.0512 | Avg: 0.0924 | LR: 1.07e-05 | Accuracy: 0.986\n2025-09-22 14:17:31 - __main__ - INFO - Валидация на шаге 3200...\n2025-09-22 14:18:05 - __main__ - INFO - Validation Loss: 0.0255 | Accuracy: 0.993\n2025-09-22 14:18:05 - __main__ - INFO - Лучшее значение! Best Eval Loss: 0.0255\n2025-09-22 14:20:16 - __main__ - INFO - Шаг 3250 | Эпоха 10 | Loss: 0.0428 | Avg: 0.0951 | LR: 1.05e-05 | Accuracy: 0.986\n2025-09-22 14:22:25 - __main__ - INFO - Шаг 3300 | Эпоха 10 | Loss: 0.0341 | Avg: 0.0922 | LR: 1.04e-05 | Accuracy: 0.987\n2025-09-22 14:24:35 - __main__ - INFO - Шаг 3350 | Эпоха 10 | Loss: 0.0493 | Avg: 0.0922 | LR: 1.02e-05 | Accuracy: 0.981\n2025-09-22 14:25:38 - __main__ - INFO - ЭПОХА 10 ЗАВЕРШЕНА | Средний Loss: 0.0471 | Accuracy: 0.986\n2025-09-22 14:25:38 - __main__ - INFO - ----------------------------------------\n2025-09-22 14:25:43 - __main__ - INFO - Финальная модель и токенизатор сохранены в 'final_model'\n2025-09-22 14:25:43 - __main__ - INFO - ============================================================\n2025-09-22 14:25:43 - __main__ - INFO - Обучение завершено!\n2025-09-22 14:25:43 - __main__ - INFO - Лучший Eval Loss: 0.0255\n2025-09-22 14:25:43 - __main__ - INFO - ============================================================\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Описание процесса чтения и парсинга тестового датасета\n\nЭтот код выполняет чтение тестового датасета из файла `dataset_1937770_3.txt`","metadata":{}},{"cell_type":"code","source":"file_path = '/kaggle/input/test-3/dataset_1937770_3.txt'\n\nparsed_data = []\nwith open(file_path, 'r', encoding='utf-8') as file:\n    \n    #Чтение файла с обработкой строк\n    \n    for line_num, line in enumerate(file, start=0):\n        line = line.strip()  \n        if not line or line.startswith('id,'):  \n            continue\n            \n        #Парсинг строк и обработка ошибок\n        \n        try:\n            id_str, text = line.split(',', 1)  \n            parsed_data.append({\n                'id': int(id_str.strip()),  \n                'text_no_spaces': text.strip()  \n            })\n        except ValueError as e:\n            print(f\"Ошибка в строке {line_num}: '{line}' — {e}\")\n            continue\n\ndf = pd.DataFrame(parsed_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T14:25:43.256782Z","iopub.execute_input":"2025-09-22T14:25:43.257036Z","iopub.status.idle":"2025-09-22T14:25:43.315020Z","shell.execute_reply.started":"2025-09-22T14:25:43.257012Z","shell.execute_reply":"2025-09-22T14:25:43.314325Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Описание функции `batch_insert_spaces`\n\nФункция `batch_insert_spaces` выполняет пакетное предсказание для задачи сегментации слов, используя модель `google/byt5-small` и её сохранённые веса. Она принимает список текстов без пробелов, добавляет к ним префикс `\"insert spaces: \"`, токенизирует, выполняет инференс модели и декодирует результаты в тексты с пробелами.\n\n### Параметры функции\n- **texts_list**: Список строк без пробелов (например, `[\"Helloworld\", \"СмартфонКнига\"]`).\n- **model_weights_path**: Путь к сохранённым весам модели (по умолчанию `\"./final_model.pt\"`).\n- **tokenizer_path**: Путь к сохранённому токенизатору (по умолчанию `\"./final_model\"`).\n- **device**: Устройство для инференса (`\"cuda\"` или `\"cpu\"`; по умолчанию определяется автоматически).\n- **batch_size**: Размер батча для обработки текстов (по умолчанию 8).","metadata":{}},{"cell_type":"code","source":"def batch_insert_spaces(texts_list, model_weights_path=\"./final_model.pt\", \n                       tokenizer_path=\"./final_model\", device=None, batch_size=8):\n    \n    logger.info(f\"Запускаем пакетное предсказание для {len(texts_list)} текстов\")\n    start_time = time.time()\n    \n    if device is None:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    try:\n        #Загрузка токенизатора\n        logger.info(f\"Загружаем токенизатор из {tokenizer_path}\")\n        tokenizer = ByT5Tokenizer.from_pretrained(tokenizer_path)\n        \n        #Создание конфигурации модели\n        config = T5Config.from_pretrained('google/byt5-small')\n\n        #Инициализация и загрузка модели\n        \n        model = T5ForConditionalGeneration(config)\n        \n        logger.info(f\"Загружаем веса модели из {model_weights_path}\")\n        checkpoint = torch.load(model_weights_path, map_location=device)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        \n        model.to(device)\n        model.eval()\n\n        #Инициализация списка результатов\n        \n        results = []\n        \n        #Пакетная обработка текстов\n        logger.info(f\"Обрабатываем файл\")\n        for i in range(0, len(texts_list), batch_size):\n            batch_texts = texts_list[i:i + batch_size]\n            batch_input_texts = [f\"insert spaces: {text}\" for text in batch_texts]\n            \n            #Токенизация батча\n            \n            inputs = tokenizer(\n                batch_input_texts, \n                return_tensors=\"pt\",\n                max_length=512,\n                truncation=True,\n                padding=True,\n                return_attention_mask=True\n            ).to(device)\n\n            #Инференс модели\n            \n            with torch.no_grad():\n                outputs = model.generate(\n                    inputs[\"input_ids\"],\n                    attention_mask=inputs[\"attention_mask\"],\n                    max_length=512,\n                    num_beams=3,\n                    early_stopping=True,\n                    length_penalty=0.8\n                )\n                \n            #Декодирование результатов\n            \n            batch_results = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n            results.extend(batch_results)\n            \n        #Логирование завершения\n        \n        execution_time = time.time() - start_time\n        logger.info(f\"Предсказание завершено за {execution_time:.2f} секунд\")\n        logger.info(f\"Обработано {len(texts_list)} текстов, среднее время: {execution_time/len(texts_list):.3f} сек/текст\")\n        \n        return results\n        \n    #Обработка ошибок\n    \n    except Exception as e:\n        logger.error(f\"Ошибка при пакетном предсказании: {str(e)}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T14:25:43.316030Z","iopub.execute_input":"2025-09-22T14:25:43.316383Z","iopub.status.idle":"2025-09-22T14:25:52.519194Z","shell.execute_reply.started":"2025-09-22T14:25:43.316353Z","shell.execute_reply":"2025-09-22T14:25:52.518440Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Описание процесса предсказания и добавления результатов в DataFrame\n\nЭтот код выполняет предсказание восстановленных текстов (с пробелами) для тестового датасета, используя функцию `batch_insert_spaces`, и добавляет результаты в DataFrame `df` в новую колонку `\"predicted_text\"`. ","metadata":{}},{"cell_type":"code","source":"test_texts = df['text_no_spaces'].tolist()\n\nrestored_texts = batch_insert_spaces(test_texts)\n\ndf[\"predicted_text\"] = restored_texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T14:25:52.520740Z","iopub.execute_input":"2025-09-22T14:25:52.520992Z","iopub.status.idle":"2025-09-22T14:27:30.099199Z","shell.execute_reply.started":"2025-09-22T14:25:52.520974Z","shell.execute_reply":"2025-09-22T14:27:30.098531Z"}},"outputs":[{"name":"stderr","text":"2025-09-22 14:25:54 - __main__ - INFO - Запускаем пакетное предсказание для 1005 текстов\n2025-09-22 14:25:54 - __main__ - INFO - Загружаем токенизатор из ./final_model\n2025-09-22 14:25:59 - __main__ - INFO - Загружаем веса модели из ./final_model.pt\n2025-09-22 14:26:02 - __main__ - INFO - Обрабатываем файл\n2025-09-22 14:27:30 - __main__ - INFO - Предсказание завершено за 95.26 секунд\n2025-09-22 14:27:30 - __main__ - INFO - Обработано 1005 текстов, среднее время: 0.095 сек/текст\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Описание функции `text_to_positions` и обработки DataFrame\n\nЭтот код выполняет преобразование предсказанных текстов с пробелами в список позиций пробелов относительно текста без пробелов и добавляет результаты в DataFrame `df` в виде новой колонки `\"predicted_positions\"`. Затем создаётся новый DataFrame `df_n`, содержащий только колонки `\"id\"` и `\"predicted_positions\"`. ","metadata":{}},{"cell_type":"code","source":"def text_to_positions(original_text, predicted_text):\n    original_text = original_text.strip()\n    predicted_text = predicted_text.strip()\n    \n    predicted_no_spaces = predicted_text.replace(\" \", \"\")\n    \n    positions = []\n    current_pos = 0\n    \n    for char in predicted_text:\n        if char == ' ':\n            positions.append(current_pos)\n        else:\n            current_pos += 1\n    \n    return str(positions)\n\ndf[\"predicted_positions\"] = df.apply(\n    lambda row: text_to_positions(row[\"text_no_spaces\"], row[\"predicted_text\"]), \n    axis=1\n)\ndf_n = df[[\"id\", \"predicted_positions\"]].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T14:27:30.100137Z","iopub.execute_input":"2025-09-22T14:27:30.100385Z","iopub.status.idle":"2025-09-22T14:27:30.146039Z","shell.execute_reply.started":"2025-09-22T14:27:30.100361Z","shell.execute_reply":"2025-09-22T14:27:30.145417Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Описание сохранения результатов в CSV\n\nЭтот код сохраняет DataFrame `df_n`, содержащий колонки `\"id\"` и `\"predicted_positions\"`, в файл `task_data_with_positions.csv` в Kaggle-ноутбуке. Также выводится сообщение в консоль, подтверждающее успешное сохранение. ","metadata":{}},{"cell_type":"code","source":"df_n.to_csv(\"task_data_with_positions.csv\", index=False, encoding=\"utf-8\")\nprint(\"✅ Данные сохранены в task_data_with_positions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T14:27:30.146803Z","iopub.execute_input":"2025-09-22T14:27:30.147059Z","iopub.status.idle":"2025-09-22T14:27:30.167722Z","shell.execute_reply.started":"2025-09-22T14:27:30.147038Z","shell.execute_reply":"2025-09-22T14:27:30.167132Z"}},"outputs":[{"name":"stdout","text":"✅ Данные сохранены в task_data_with_positions.csv\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"df_n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T14:28:13.419391Z","iopub.execute_input":"2025-09-22T14:28:13.419913Z","iopub.status.idle":"2025-09-22T14:28:13.452261Z","shell.execute_reply.started":"2025-09-22T14:28:13.419889Z","shell.execute_reply":"2025-09-22T14:28:13.451693Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"        id  predicted_positions\n0        0       [5, 7, 10, 12]\n1        1        [3, 6, 7, 10]\n2        2  [4, 12, 13, 20, 21]\n3        3          [5, 10, 18]\n4        4           [2, 5, 10]\n...    ...                  ...\n1000  1000                  [3]\n1001  1001          [7, 10, 16]\n1002  1002                 [19]\n1003  1003          [9, 20, 23]\n1004  1004              [9, 12]\n\n[1005 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predicted_positions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[5, 7, 10, 12]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[3, 6, 7, 10]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>[4, 12, 13, 20, 21]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>[5, 10, 18]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>[2, 5, 10]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1000</th>\n      <td>1000</td>\n      <td>[3]</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>1001</td>\n      <td>[7, 10, 16]</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>1002</td>\n      <td>[19]</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>1003</td>\n      <td>[9, 20, 23]</td>\n    </tr>\n    <tr>\n      <th>1004</th>\n      <td>1004</td>\n      <td>[9, 12]</td>\n    </tr>\n  </tbody>\n</table>\n<p>1005 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":21}]}